name: Instagram Reel Checker

on:
  schedule:
    # Run daily at 8 PM IST (2:30 PM UTC)
    - cron: '30 14 * * *'  # Daily at 8 PM IST
  workflow_dispatch:
    inputs:
      force_check:
        description: 'Force check both accounts'
        required: false
        type: boolean
        default: false

env:
  PRIMARY_ACCOUNT: ${{ secrets.PRIMARY_INSTA_USERNAME }}
  BACKUP_ACCOUNT: ${{ secrets.BACKUP_INSTA_USERNAME }}
  AIRTABLE_TOKEN: ${{ secrets.AIRTABLE_TOKEN }}
  AIRTABLE_BASE_ID: ${{ secrets.AIRTABLE_BASE_ID }}
  AIRTABLE_TABLE_ID: ${{ secrets.AIRTABLE_TABLE_ID }}

jobs:
  check-accounts:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.12
          
      - name: Cache Python packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-insta-checker
          restore-keys: |
            ${{ runner.os }}-pip-
                
      - name: Install Dependencies
        run: |
          pip install -U requests python-dateutil instascrape beautifulsoup4
          
      - name: Write Instagram Cookies
        run: |
          echo "${{ secrets.INSTA_COOKIES }}" > cookies.txt
          echo "${{ secrets.BACKUP_INSTA_COOKIES }}" > backup_cookies.txt
          
      - name: Create Instagram Scraper Script      - name: Create Instagram Scraper Script
        run: |
          cat > check_instagram.py << 'EOF'
          import json
          import requests
          import sys
          from datetime import datetime, timedelta
          import os
          from instascrape import Profile, Reel
          import time
          
          def get_airtable_processed_urls():
              """Get list of already processed Instagram URLs from Airtable"""
              try:
                  headers = {
                      'Authorization': f'Bearer {os.environ["AIRTABLE_TOKEN"]}',
                      'Content-Type': 'application/json'
                  }
                  
                  url = f'https://api.airtable.com/v0/{os.environ["AIRTABLE_BASE_ID"]}/{os.environ["AIRTABLE_TABLE_ID"]}'
                  response = requests.get(url, headers=headers, timeout=30)
                  response.raise_for_status()
                  
                  processed_urls = set()
                  data = response.json()
                  
                  for record in data.get('records', []):
                      fields = record.get('fields', {})
                      if 'url' in fields:
                          processed_urls.add(fields['url'])
                  
                  return processed_urls
              except Exception as e:
                  print(f"Error fetching Airtable data: {e}")
                  return set()
          
          def setup_session_with_cookies(cookies_file):
              """Setup requests session with Instagram cookies"""
              session = requests.Session()
              
              # Set headers to mimic a real browser
              session.headers.update({
                  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                  'Accept-Language': 'en-US,en;q=0.5',
                  'Accept-Encoding': 'gzip, deflate',
                  'Connection': 'keep-alive',
                  'Upgrade-Insecure-Requests': '1',
              })
              
              # Load cookies from file
              try:
                  with open(cookies_file, 'r') as f:
                      cookie_content = f.read().strip()
                  
                  # Handle different cookie formats
                  if cookie_content.startswith('{') or cookie_content.startswith('['):
                      # JSON format
                      cookies_data = json.loads(cookie_content)
                      if isinstance(cookies_data, list):
                          for cookie in cookies_data:
                              session.cookies.set(cookie['name'], cookie['value'], domain='.instagram.com')
                      else:
                          for name, value in cookies_data.items():
                              session.cookies.set(name, value, domain='.instagram.com')
                  else:
                      # Simple format: name=value
                      for line in cookie_content.split('\n'):
                          if '=' in line and not line.startswith('#'):
                              name, value = line.split('=', 1)
                              session.cookies.set(name.strip(), value.strip(), domain='.instagram.com')
                              
                  print(f"Loaded {len(session.cookies)} cookies from {cookies_file}")
                  return session
                  
              except Exception as e:
                  print(f"Error loading cookies from {cookies_file}: {e}")
                  return session
          
          def get_recent_reels(username, cookies_file, max_items=10):
              """Get recent reels from Instagram profile using instascrape"""
              try:
                  print(f"Scraping reels for {username}...")
                  
                  # Setup session with cookies
                  session = setup_session_with_cookies(cookies_file)
                  
                  # Create profile instance
                  profile = Profile(username)
                  
                  # Try to scrape profile with session
                  try:
                      profile.scrape(session=session)
                  except Exception as e:
                      print(f"Error scraping profile {username}: {e}")
                      # Try without session as fallback
                      profile.scrape()
                  
                  print(f"Profile loaded: {profile.username} ({profile.followers} followers)")
                  
                  # Get recent posts
                  recent_posts = profile.get_recent_posts(amount=max_items * 2)  # Get more to filter for reels
                  
                  reels = []
                  for post in recent_posts:
                      try:
                          # Check if post is a reel (video content)
                          if hasattr(post, 'is_video') and post.is_video:
                              # Try to get more details about the post
                              post.scrape(session=session)
                              
                              # Check if it's actually a reel (short video)
                              if hasattr(post, 'video_duration') and post.video_duration and post.video_duration <= 90:
                                  reel_url = f"https://www.instagram.com/reel/{post.shortcode}/"
                                  
                                  reel_data = {
                                      'url': reel_url,
                                      'title': post.caption[:100] if hasattr(post, 'caption') and post.caption else f'Reel from {username}',
                                      'upload_date': post.upload_date.strftime('%Y%m%d') if hasattr(post, 'upload_date') and post.upload_date else datetime.now().strftime('%Y%m%d'),
                                      'id': post.shortcode,
                                      'duration': post.video_duration if hasattr(post, 'video_duration') else 0,
                                      'likes': post.likes if hasattr(post, 'likes') else 0
                                  }
                                  
                                  reels.append(reel_data)
                                  print(f"Found reel: {reel_url} (Duration: {reel_data['duration']}s)")
                                  
                                  if len(reels) >= max_items:
                                      break
                                      
                          # Add delay to avoid rate limiting
                          time.sleep(1)
                          
                      except Exception as e:
                          print(f"Error processing post: {e}")
                          continue
                  
                  print(f"Found {len(reels)} reels for {username}")
                  return reels
                  
              except Exception as e:
                  print(f"Error getting reels for {username}: {e}")
                  # Fallback to manual mode if scraping fails
                  return get_fallback_reels(username)
          
          def get_fallback_reels(username):
              """Fallback method with some example reels if scraping fails"""
              print(f"Using fallback mode for {username}")
              # Return empty list - you could add manual URLs here as backup
              return []
          
          def is_recent_reel(upload_date, hours=24):
              """Check if reel was uploaded within specified hours"""
              if not upload_date:
                  return True  # Assume recent if no date
              
              try:
                  if len(upload_date) == 8 and upload_date.isdigit():
                      upload_dt = datetime.strptime(upload_date, '%Y%m%d')
                      cutoff = datetime.now() - timedelta(hours=hours)
                      return upload_dt >= cutoff
                  return True  # Assume recent if can't parse
              except Exception:
                  return True  # Assume recent on error
          
          def main():
              force_check = os.environ.get('FORCE_CHECK', 'false').lower() == 'true'
              
              print("=== Instagram Reel Checker (InstaScrape Mode) ===")
              print(f"Force check: {force_check}")
              print("Note: Using instascrape library for automatic reel detection")
              
              # Get processed URLs from Airtable
              processed_urls = get_airtable_processed_urls()
              print(f"Found {len(processed_urls)} already processed URLs")
              
              # Check accounts
              primary_account = os.environ.get('PRIMARY_ACCOUNT')
              backup_account = os.environ.get('BACKUP_ACCOUNT')
              
              selected_reel = None
              account_type = None
              
              # Check primary account first
              if primary_account:
                  print(f"\nChecking primary account: {primary_account}")
                  try:
                      primary_reels = get_recent_reels(primary_account, 'cookies.txt')
                      print(f"Found {len(primary_reels)} reels from primary account")
                      
                      for i, reel in enumerate(primary_reels):
                          print(f"  Reel {i+1}: {reel['url']} (Likes: {reel.get('likes', 0)})")
                          if reel['url'] not in processed_urls:
                              if force_check or is_recent_reel(reel['upload_date']):
                                  selected_reel = reel
                                  account_type = 'primary'
                                  print(f"  ‚úì SELECTED: {reel['url']}")
                                  break
                              else:
                                  print(f"  - Skipped (not recent)")
                          else:
                              print(f"  - Skipped (already processed)")
                  except Exception as e:
                      print(f"Error checking primary account: {e}")
              
              # Check backup account if no reel selected
              if not selected_reel and backup_account:
                  print(f"\nChecking backup account: {backup_account}")
                  try:
                      backup_reels = get_recent_reels(backup_account, 'backup_cookies.txt')
                      print(f"Found {len(backup_reels)} reels from backup account")
                      
                      for i, reel in enumerate(backup_reels):
                          print(f"  Reel {i+1}: {reel['url']} (Likes: {reel.get('likes', 0)})")
                          if reel['url'] not in processed_urls:
                              if force_check or is_recent_reel(reel['upload_date']):
                                  selected_reel = reel
                                  account_type = 'backup'
                                  print(f"  ‚úì SELECTED: {reel['url']}")
                                  break
                              else:
                                  print(f"  - Skipped (not recent)")
                          else:
                              print(f"  - Skipped (already processed)")
                  except Exception as e:
                      print(f"Error checking backup account: {e}")
              
              # Output results
              if selected_reel:
                  output = {
                      'found_reel': True,
                      'url': selected_reel['url'],
                      'title': selected_reel['title'],
                      'account_type': account_type,
                      'upload_date': selected_reel['upload_date'],
                      'likes': selected_reel.get('likes', 0),
                      'duration': selected_reel.get('duration', 0)
                  }
                  
                  with open('reel_check_result.json', 'w') as f:
                      json.dump(output, f, indent=2)
                  
                  print(f"\nüéâ SUCCESS: Selected reel from {account_type} account")
                  print(f"URL: {selected_reel['url']}")
                  print(f"Likes: {selected_reel.get('likes', 0)}")
                  print(f"Duration: {selected_reel.get('duration', 0)}s")
                  
                  # Set GitHub Actions outputs
                  with open(os.environ.get('GITHUB_OUTPUT', '/dev/null'), 'a') as f:
                      f.write(f"found_reel=true\n")
                      f.write(f"reel_url={selected_reel['url']}\n")
                      f.write(f"account_type={account_type}\n")
                  
                  return 0
              else:
                  print(f"\n‚ùå No new reels found")
                  print("üí° This could mean:")
                  print("   - No new reels posted recently")
                  print("   - All recent reels already processed")
                  print("   - Instagram scraping limitations")
                  print("   - Cookie authentication issues")
                  
                  with open(os.environ.get('GITHUB_OUTPUT', '/dev/null'), 'a') as f:
                      f.write(f"found_reel=false\n")
                  
                  return 0
          
          if __name__ == "__main__":
              sys.exit(main())
          EOF
          
      - name: Check for New Reels
        id: check_reels
        env:
          FORCE_CHECK: ${{ github.event.inputs.force_check }}
        run: python check_instagram.py
        
      - name: Trigger Download Workflow
        if: steps.check_reels.outputs.found_reel == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const response = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'download.yml',
              ref: 'main',
              inputs: {
                url: '${{ steps.check_reels.outputs.reel_url }}',
                account_type: '${{ steps.check_reels.outputs.account_type }}'
              }
            });
            
            console.log('‚úÖ Triggered download workflow for:', '${{ steps.check_reels.outputs.reel_url }}');
              - name: Upload Check Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: reel-check-results
          path: |
            reel_check_result.json
            cookies.txt
            backup_cookies.txt
          retention-days: 1
          
      - name: Show Status
        if: always()
        run: |
          echo ""
          echo "ü§ñ Instagram Reel Checker Status:"
          echo "================================="
          echo ""
          echo "‚úÖ Using InstaScrape library for automatic reel detection"
          echo "‚úÖ Checking both primary and backup accounts"
          echo "‚úÖ Airtable integration for duplicate prevention"
          echo "‚úÖ Automatic download workflow triggering"
          echo ""
          if [ "${{ steps.check_reels.outputs.found_reel }}" = "true" ]; then
            echo "üéâ SUCCESS: Found and selected a new reel!"
            echo "üîó URL: ${{ steps.check_reels.outputs.reel_url }}"
            echo "üì± Account: ${{ steps.check_reels.outputs.account_type }}"
          else
            echo "‚ÑπÔ∏è  No new reels found this time"
            echo "üí° This is normal - it means either:"
            echo "   ‚Ä¢ No new reels posted recently"
            echo "   ‚Ä¢ All recent reels already processed"
          fi
