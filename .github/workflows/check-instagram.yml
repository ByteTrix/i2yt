name: Instagram Reel Checker

on:
  schedule:
    # Run daily at 8 PM IST (2:30 PM UTC)
    - cron: '30 14 * * *'  # Daily at 8 PM IST
  workflow_dispatch:
    inputs:
      force_check:
        description: 'Force check both accounts'
        required: false
        type: boolean
        default: false

env:
  PRIMARY_ACCOUNT: ${{ secrets.PRIMARY_INSTA_USERNAME }}
  BACKUP_ACCOUNT: ${{ secrets.BACKUP_INSTA_USERNAME }}
  AIRTABLE_TOKEN: ${{ secrets.AIRTABLE_TOKEN }}
  AIRTABLE_BASE_ID: ${{ secrets.AIRTABLE_BASE_ID }}
  AIRTABLE_TABLE_ID: ${{ secrets.AIRTABLE_TABLE_ID }}

jobs:
  check-accounts:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.12
          
      - name: Cache Python packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-insta-checker
          restore-keys: |
            ${{ runner.os }}-pip-
                
      - name: Install Dependencies
        run: |
          pip install -U requests python-dateutil instascrape beautifulsoup4
          
      - name: Write Instagram Cookies
        run: |
          echo "${{ secrets.INSTA_COOKIES }}" > cookies.txt
          echo "${{ secrets.BACKUP_INSTA_COOKIES }}" > backup_cookies.txt
          
      - name: Create Instagram Scraper Script      - name: Create Instagram Scraper Script
        run: |
          cat > check_instagram.py << 'EOF'
          import json
          import requests
          import sys
          from datetime import datetime, timedelta
          import os
          from instascrape import Profile, Reel
          import time
          
          def get_airtable_processed_urls():
              """Get list of already processed Instagram URLs from Airtable"""
              try:
                  headers = {
                      'Authorization': f'Bearer {os.environ["AIRTABLE_TOKEN"]}',
                      'Content-Type': 'application/json'
                  }
                  
                  url = f'https://api.airtable.com/v0/{os.environ["AIRTABLE_BASE_ID"]}/{os.environ["AIRTABLE_TABLE_ID"]}'
                  response = requests.get(url, headers=headers, timeout=30)
                  response.raise_for_status()
                  
                  processed_urls = set()
                  data = response.json()
                  
                  for record in data.get('records', []):
                      fields = record.get('fields', {})
                      if 'url' in fields:
                          processed_urls.add(fields['url'])
                  
                  return processed_urls
              except Exception as e:
                  print(f"Error fetching Airtable data: {e}")
                  return set()
          
          def setup_session_with_cookies(cookies_file):
              """Setup requests session with Instagram cookies"""
              session = requests.Session()
              
              # Set headers to mimic a real browser
              session.headers.update({
                  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                  'Accept-Language': 'en-US,en;q=0.5',
                  'Accept-Encoding': 'gzip, deflate',
                  'Connection': 'keep-alive',
                  'Upgrade-Insecure-Requests': '1',
              })
              
              # Load cookies from file
              try:
                  with open(cookies_file, 'r') as f:
                      cookie_content = f.read().strip()
                  
                  # Handle different cookie formats
                  if cookie_content.startswith('{') or cookie_content.startswith('['):
                      # JSON format
                      cookies_data = json.loads(cookie_content)
                      if isinstance(cookies_data, list):
                          for cookie in cookies_data:
                              session.cookies.set(cookie['name'], cookie['value'], domain='.instagram.com')
                      else:
                          for name, value in cookies_data.items():
                              session.cookies.set(name, value, domain='.instagram.com')
                  else:
                      # Simple format: name=value
                      for line in cookie_content.split('\n'):
                          if '=' in line and not line.startswith('#'):
                              name, value = line.split('=', 1)
                              session.cookies.set(name.strip(), value.strip(), domain='.instagram.com')
                              
                  print(f"Loaded {len(session.cookies)} cookies from {cookies_file}")
                  return session
                  
              except Exception as e:
                  print(f"Error loading cookies from {cookies_file}: {e}")
                  return session
          
          def get_recent_reels(username, cookies_file, max_items=10):
              """Get recent reels from Instagram profile using instascrape"""
              try:
                  print(f"Scraping reels for {username}...")
                  
                  # Setup session with cookies
                  session = setup_session_with_cookies(cookies_file)
                  
                  # Create profile instance
                  profile = Profile(username)
                  
                  # Try to scrape profile with session
                  try:
                      profile.scrape(session=session)
                  except Exception as e:
                      print(f"Error scraping profile {username}: {e}")
                      # Try without session as fallback
                      profile.scrape()
                  
                  print(f"Profile loaded: {profile.username} ({profile.followers} followers)")
                  
                  # Get recent posts
                  recent_posts = profile.get_recent_posts(amount=max_items * 2)  # Get more to filter for reels
                  
                  reels = []
                  for post in recent_posts:
                      try:
                          # Check if post is a reel (video content)
                          if hasattr(post, 'is_video') and post.is_video:
                              # Try to get more details about the post
                              post.scrape(session=session)
                              
                              # Check if it's actually a reel (short video)
                              if hasattr(post, 'video_duration') and post.video_duration and post.video_duration <= 90:
                                  reel_url = f"https://www.instagram.com/reel/{post.shortcode}/"
                                  
                                  reel_data = {
                                      'url': reel_url,
                                      'title': post.caption[:100] if hasattr(post, 'caption') and post.caption else f'Reel from {username}',
                                      'upload_date': post.upload_date.strftime('%Y%m%d') if hasattr(post, 'upload_date') and post.upload_date else datetime.now().strftime('%Y%m%d'),
                                      'id': post.shortcode,
                                      'duration': post.video_duration if hasattr(post, 'video_duration') else 0,
                                      'likes': post.likes if hasattr(post, 'likes') else 0
                                  }
                                  
                                  reels.append(reel_data)
                                  print(f"Found reel: {reel_url} (Duration: {reel_data['duration']}s)")
                                  
                                  if len(reels) >= max_items:
                                      break
                                      
                          # Add delay to avoid rate limiting
                          time.sleep(1)
                          
                      except Exception as e:
                          print(f"Error processing post: {e}")
                          continue
                  
                  print(f"Found {len(reels)} reels for {username}")
                  return reels
                  
              except Exception as e:
                  print(f"Error getting reels for {username}: {e}")
                  # Fallback to manual mode if scraping fails
                  return get_fallback_reels(username)
          
          def get_fallback_reels(username):
              """Fallback method with some example reels if scraping fails"""
              print(f"Using fallback mode for {username}")
              # Return empty list - you could add manual URLs here as backup
              return []
          
          def is_recent_reel(upload_date, hours=24):
              """Check if reel was uploaded within specified hours"""
              if not upload_date:
                  return True  # Assume recent if no date
              
              try:
                  if len(upload_date) == 8 and upload_date.isdigit():
                      upload_dt = datetime.strptime(upload_date, '%Y%m%d')
                      cutoff = datetime.now() - timedelta(hours=hours)
                      return upload_dt >= cutoff
                  return True  # Assume recent if can't parse
              except Exception:
                  return True  # Assume recent on error
          
          def main():
              force_check = os.environ.get('FORCE_CHECK', 'false').lower() == 'true'
              
              print("=== Instagram Reel Checker (InstaScrape Mode) ===")
              print(f"Force check: {force_check}")
              print("Note: Using instascrape library for automatic reel detection")
              
              # Get processed URLs from Airtable
              processed_urls = get_airtable_processed_urls()
              print(f"Found {len(processed_urls)} already processed URLs")
              
              # Check accounts
              primary_account = os.environ.get('PRIMARY_ACCOUNT')
              backup_account = os.environ.get('BACKUP_ACCOUNT')
              
              selected_reel = None
              account_type = None
              
              # Check primary account first
              if primary_account:
                  print(f"\nChecking primary account: {primary_account}")
                  try:
                      primary_reels = get_recent_reels(primary_account, 'cookies.txt')
                      print(f"Found {len(primary_reels)} reels from primary account")
                      
                      for i, reel in enumerate(primary_reels):
                          print(f"  Reel {i+1}: {reel['url']} (Likes: {reel.get('likes', 0)})")
                          if reel['url'] not in processed_urls:
                              if force_check or is_recent_reel(reel['upload_date']):
                                  selected_reel = reel
                                  account_type = 'primary'
                                  print(f"  ✓ SELECTED: {reel['url']}")
                                  break
                              else:
                                  print(f"  - Skipped (not recent)")
                          else:
                              print(f"  - Skipped (already processed)")
                  except Exception as e:
                      print(f"Error checking primary account: {e}")
              
              # Check backup account if no reel selected
              if not selected_reel and backup_account:
                  print(f"\nChecking backup account: {backup_account}")
                  try:
                      backup_reels = get_recent_reels(backup_account, 'backup_cookies.txt')
                      print(f"Found {len(backup_reels)} reels from backup account")
                      
                      for i, reel in enumerate(backup_reels):
                          print(f"  Reel {i+1}: {reel['url']} (Likes: {reel.get('likes', 0)})")
                          if reel['url'] not in processed_urls:
                              if force_check or is_recent_reel(reel['upload_date']):
                                  selected_reel = reel
                                  account_type = 'backup'
                                  print(f"  ✓ SELECTED: {reel['url']}")
                                  break
                              else:
                                  print(f"  - Skipped (not recent)")
                          else:
                              print(f"  - Skipped (already processed)")
                  except Exception as e:
                      print(f"Error checking backup account: {e}")
              
              # Output results
              if selected_reel:
                  output = {
                      'found_reel': True,
                      'url': selected_reel['url'],
                      'title': selected_reel['title'],
                      'account_type': account_type,
                      'upload_date': selected_reel['upload_date'],
                      'likes': selected_reel.get('likes', 0),
                      'duration': selected_reel.get('duration', 0)
                  }
                  
                  with open('reel_check_result.json', 'w') as f:
                      json.dump(output, f, indent=2)
                  
                  print(f"\n🎉 SUCCESS: Selected reel from {account_type} account")
                  print(f"URL: {selected_reel['url']}")
                  print(f"Likes: {selected_reel.get('likes', 0)}")
                  print(f"Duration: {selected_reel.get('duration', 0)}s")
                  
                  # Set GitHub Actions outputs
                  with open(os.environ.get('GITHUB_OUTPUT', '/dev/null'), 'a') as f:
                      f.write(f"found_reel=true\n")
                      f.write(f"reel_url={selected_reel['url']}\n")
                      f.write(f"account_type={account_type}\n")
                  
                  return 0
              else:
                  print(f"\n❌ No new reels found")
                  print("💡 This could mean:")
                  print("   - No new reels posted recently")
                  print("   - All recent reels already processed")
                  print("   - Instagram scraping limitations")
                  print("   - Cookie authentication issues")
                  
                  with open(os.environ.get('GITHUB_OUTPUT', '/dev/null'), 'a') as f:
                      f.write(f"found_reel=false\n")
                  
                  return 0
          
          if __name__ == "__main__":
              sys.exit(main())
          EOF
          
      - name: Check for New Reels
        id: check_reels
        env:
          FORCE_CHECK: ${{ github.event.inputs.force_check }}
        run: python check_instagram.py
        
      - name: Trigger Download Workflow
        if: steps.check_reels.outputs.found_reel == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const response = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'download.yml',
              ref: 'main',
              inputs: {
                url: '${{ steps.check_reels.outputs.reel_url }}',
                account_type: '${{ steps.check_reels.outputs.account_type }}'
              }
            });
            
            console.log('✅ Triggered download workflow for:', '${{ steps.check_reels.outputs.reel_url }}');
              - name: Upload Check Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: reel-check-results
          path: |
            reel_check_result.json
            cookies.txt
            backup_cookies.txt
          retention-days: 1
          
      - name: Show Status
        if: always()
        run: |
          echo ""
          echo "🤖 Instagram Reel Checker Status:"
          echo "================================="
          echo ""
          echo "✅ Using InstaScrape library for automatic reel detection"
          echo "✅ Checking both primary and backup accounts"
          echo "✅ Airtable integration for duplicate prevention"
          echo "✅ Automatic download workflow triggering"
          echo ""
          if [ "${{ steps.check_reels.outputs.found_reel }}" = "true" ]; then
            echo "🎉 SUCCESS: Found and selected a new reel!"
            echo "🔗 URL: ${{ steps.check_reels.outputs.reel_url }}"
            echo "📱 Account: ${{ steps.check_reels.outputs.account_type }}"
          else
            echo "ℹ️  No new reels found this time"
            echo "💡 This is normal - it means either:"
            echo "   • No new reels posted recently"
            echo "   • All recent reels already processed"
          fi
